// SPDX-License-Identifier: Apache-2.0 OR MIT OR Unlicense

// This is "kernel 4" in a 4-kernel pipeline. It renders the commands
// in the per-tile command list to an image.

// Right now, this kernel stores the image in a buffer, but a better
// plan is to use a texture. This is because of limited support.

#version 450
#extension GL_GOOGLE_include_directive : enable

#include "mem.h"
#include "setup.h"

#define CHUNK_X 2
#define CHUNK_Y 4
#define CHUNK (CHUNK_X * CHUNK_Y)
#define CHUNK_DX (TILE_WIDTH_PX / CHUNK_X)
#define CHUNK_DY (TILE_HEIGHT_PX / CHUNK_Y)
layout(local_size_x = CHUNK_DX, local_size_y = CHUNK_DY) in;

layout(set = 0, binding = 1) restrict readonly buffer ConfigBuf {
    Config conf;
};

layout(rgba8, set = 0, binding = 2) uniform restrict writeonly image2D image;

layout(rgba8, set = 0, binding = 3) uniform restrict readonly image2D image_atlas;

layout(rgba8, set = 0, binding = 4) uniform restrict readonly image2D gradients;

#include "ptcl.h"
#include "tile.h"

#define MAX_BLEND_STACK 128

shared int cov[TILE_HEIGHT_PX * TILE_WIDTH_PX];

#define COV(x, y) cov[(x) + (y)*TILE_WIDTH_PX]
#define COV_MULTIPLIER 65536.0

mediump vec3 tosRGB(mediump vec3 rgb) {
    bvec3 cutoff = greaterThanEqual(rgb, vec3(0.0031308));
    mediump vec3 below = vec3(12.92) * rgb;
    mediump vec3 above = vec3(1.055) * pow(rgb, vec3(0.41666)) - vec3(0.055);
    return mix(below, above, cutoff);
}

mediump vec3 fromsRGB(mediump vec3 srgb) {
    // Formula from EXT_sRGB.
    bvec3 cutoff = greaterThanEqual(srgb, vec3(0.04045));
    mediump vec3 below = srgb / vec3(12.92);
    mediump vec3 above = pow((srgb + vec3(0.055)) / vec3(1.055), vec3(2.4));
    return mix(below, above, cutoff);
}

// unpacksRGB unpacks a color in the sRGB color space to a vec4 in the linear color
// space.
mediump vec4 unpacksRGB(uint srgba) {
    mediump vec4 color = unpackUnorm4x8(srgba).wzyx;
    return vec4(fromsRGB(color.rgb), color.a);
}

// packsRGB packs a color in the linear color space into its 8-bit sRGB equivalent.
uint packsRGB(mediump vec4 rgba) {
    rgba = vec4(tosRGB(rgba.rgb), rgba.a);
    return packUnorm4x8(rgba.wzyx);
}

uvec2 chunk_offset(uint i) {
    return uvec2(i % CHUNK_X * CHUNK_DX, i / CHUNK_X * CHUNK_DY);
}

mediump vec4[CHUNK] fillImage(uvec2 xy, CmdImage cmd_img) {
    mediump vec4 rgba[CHUNK];
    for (uint i = 0; i < CHUNK; i++) {
        ivec2 uv = ivec2(xy + chunk_offset(i)) + cmd_img.offset;
        mediump vec4 fg_rgba;
        fg_rgba = imageLoad(image_atlas, uv);
        fg_rgba.rgb = fromsRGB(fg_rgba.rgb);
        rgba[i] = fg_rgba;
    }
    return rgba;
}

void main() {
    uint tile_ix = gl_WorkGroupID.y * conf.width_in_tiles + gl_WorkGroupID.x;
    Alloc cmd_alloc = slice_mem(conf.ptcl_alloc, tile_ix * PTCL_INITIAL_ALLOC, PTCL_INITIAL_ALLOC);
    CmdRef cmd_ref = CmdRef(cmd_alloc.offset);

    uint th_ix = gl_LocalInvocationIndex;
    uvec2 xy_uint = uvec2(gl_LocalInvocationID.x + TILE_WIDTH_PX * gl_WorkGroupID.x,
                          gl_LocalInvocationID.y + TILE_HEIGHT_PX * gl_WorkGroupID.y);
    vec2 xy = vec2(xy_uint);
    mediump vec4 rgba[CHUNK];
    uint blend_stack[MAX_BLEND_STACK][CHUNK];
    mediump float blend_alpha_stack[MAX_BLEND_STACK][CHUNK];
    for (uint i = 0; i < CHUNK; i++) {
        rgba[i] = vec4(0.0);
    }

    mediump float area[CHUNK];
    uint clip_depth = 0;
    bool mem_ok = mem_error == NO_ERROR;
    while (mem_ok) {
        uint tag = Cmd_tag(cmd_alloc, cmd_ref).tag;
        if (tag == Cmd_End) {
            break;
        }
        switch (tag) {
        case Cmd_Stroke:
            // Calculate distance field from all the line segments in this tile.
            CmdStroke stroke = Cmd_Stroke_read(cmd_alloc, cmd_ref);
            mediump float df[CHUNK];
            for (uint k = 0; k < CHUNK; k++)
                df[k] = 1e9;
            TileSegRef tile_seg_ref = TileSegRef(stroke.tile_ref);
            do {
                TileSeg seg = TileSeg_read(new_alloc(tile_seg_ref.offset, TileSeg_size, mem_ok), tile_seg_ref);
                vec2 line_vec = seg.vector;
                for (uint k = 0; k < CHUNK; k++) {
                    vec2 dpos = gl_LocalInvocationID.xy + vec2(chunk_offset(k)) + vec2(0.5, 0.5) - seg.origin;
                    float t = clamp(dot(line_vec, dpos) / dot(line_vec, line_vec), 0.0, 1.0);
                    df[k] = min(df[k], length(line_vec * t - dpos));
                }
                tile_seg_ref = seg.next;
            } while (tile_seg_ref.offset != 0);
            for (uint k = 0; k < CHUNK; k++) {
                area[k] = clamp(stroke.half_width + 0.5 - df[k], 0.0, 1.0);
            }
            cmd_ref.offset += 4 + CmdStroke_size;
            break;
        case Cmd_Fill:
            CmdFill fill = Cmd_Fill_read(cmd_alloc, cmd_ref);
            tile_seg_ref = TileSegRef(fill.tile_ref);
            for (uint k = 0; k < CHUNK; k++) {
                uint i = gl_LocalInvocationIndex + k * gl_WorkGroupSize.x * gl_WorkGroupSize.y;
                area[k] = float(fill.backdrop);
                cov[i] = 0;
            }
            // Calculate coverage based on backdrop + coverage of each line segment
            do {
                TileSeg seg = TileSeg_read(new_alloc(tile_seg_ref.offset, TileSeg_size, mem_ok), tile_seg_ref);
                vec2 start_o = seg.origin;
                vec2 vec = seg.vector;
                // First, do a fast and non-antialiased calculation of coverage at the left top corner of each pixel.
                // We first shoot a ray to the left to get the horizontal winding change using an implicit test.
                // Then we start from the left edge and go up, testing for a vertical winding change using an implicit
                // test again.
                //
                // To solve degenerate cases, we derive a tiebreaking rule by deliberately modifying the problem we are
                // solving. Since it is hard to reason about the behavior when the tested point is right on the line, we
                // move the tested point slightly in a way that it will never reside on an edge. Let ε be an
                // arbitrarily small positve number. We shift the point by (ε^2, ε). This points toward an angle that is
                // arbitrarily close to the x axis. (The reason that we shift x by ε^2 is because sometimes the line is
                // completely vertical, which means that a shift by (0, ε) still makes it land on the line.) The
                // shift being positive means that it stays inside the bounds of tile, preventing another potential
                // source of issues.
                // Now we derive a rule that is free of this imaginary ε. When we encounter zeroes in an implicit test,
                // moving y to y+ε would change the sign to sign(-n.y). (Note that start = seg.origin - point, so the
                // sign is reversed.) If n.y is zero, then we move x to x+ε^2, which gives us the sign of sign(-n.x).
                // As an optimization, we pick the direction of the normal vector so that the shift will always make
                // the implicit test move toward negative values. Zeroes are therefore always treated like negative
                // values.
                // We also need a rule for testing whether the point resides in the segment's x or y range. Since we
                // shift by an positive amount, this means that a range of [xmin, xmax] becomes [xmin, xmax). Testing
                // for [xmin, xmax) can be done through ((xmin - x) > 0 != (xmax - x) > 0). Same for y.
                vec2 n;
                uint negate_mask = ((seg.flags & TILESEG_NORMAL_NEGATE_X) * ((1 << 31) / TILESEG_NORMAL_NEGATE_X));
                n.x = uintBitsToFloat(floatBitsToUint(vec.y) ^ negate_mask);
                n.y = abs(vec.x);
                for (uint j = 0; j < CHUNK_Y; j++) {
                    float my_y = gl_LocalInvocationID.y + CHUNK_DY * j;
                    for (uint i = 0; i < CHUNK_X; i++) {
                        float my_x = gl_LocalInvocationID.x + CHUNK_DX * i;
                        vec2 start = seg.origin - vec2(my_x, my_y);
                        float outer_x0 = dot(vec2(start_o.x, start.y), n);
                        float outer = dot(start, n);
                        bool change = (outer > 0 != outer_x0 > 0);
                        change = change && (start.y > 0 != (start.y + vec.y) > 0);
                        bool has_left_edge = (seg.flags & TILESEG_HAS_LEFT_EDGE) != 0;
                        bool y_edge = outer_x0 <= 0 && has_left_edge;
                        change = change != y_edge;
                        if (change)
                            area[j * CHUNK_X + i] += !has_left_edge ? -sign(vec.y) : sign(vec.x);
                    }
                }

                // Determine antialiased coverage, only for tiles that might be touched by the line.
                // The coverage and winding is relative to the top left corner of the pixel, and we do the winding test
                // in the same left -> top order as the non-AA pass.
                // This means that the overall winding is determined through:
                //   left (pixel) -> top (pixel) -> left (tile) -> top (tile)
                // and this is not always equal to directly doing left -> top to the tile's top left corner.
                // However, when the winding is summed over a closed path, the integral matches (cf. Stokes' theorem).

                // Drawing ideas from the Digital Differential Analyzer algorithm, we swap the axis if dy/dx < 1.
                // This means that only up to two pixels with the same y value can be touched by the line.
                // We can now dedicate 2 threads per y value to process the sparse coverage.
                bool swap_xy = abs(vec.y) < abs(vec.x);
                if (th_ix < TILE_WIDTH_PX * 2) { // TILE_WIDTH_PX must be equal to TILE_HEIGHT_PX
                    bool low_side = th_ix < TILE_WIDTH_PX;
                    uint i = th_ix % TILE_WIDTH_PX;
                    vec2 start = seg.origin;
                    if (swap_xy) {
                        start = start.yx;
                        vec = vec.yx;
                    }
                    start.y -= i;
                    vec2 end = start + vec;
                    vec2 ywindow = clamp(vec2(start.y, end.y), 0.0, 1.0);
                    // Use the unclamped point as the origin. This ensures that we get the accurate start and end
                    // coordinates.
                    vec2 t = (ywindow - vec2(start.y, end.y)) / vec.y;
                    vec2 x_tmp = vec2(start.x, end.x) + t * vec.x;
                    // The line segment limited to ywindow can span max 1 pixel in x coordinates. When bounded by pixels
                    // with integer x, it will span max 2 pixels. There are a few way to bound in a way to satisfy the
                    // conditions. The following is the only one that can deal with the edge cases:
                    // 1. If both x_tmp.x and x_tmp.y is out of bounds, then the inferred ywindow will have a garbage
                    //    value as well. It is rejected by ywindow.x != ywindow.y in the condition below, unless...
                    // 2. If vec.x is 0, then ywindow doesn't get rescaled at all and it will pass to inequality. We
                    //    need to ensure that the calculated coverage is 0 in this case so it ends up being a noop.
                    //    Using max(x_tmp) as the base means that the out-of-bound cell will get its xwindow clamped to
                    //    two 1.0s, which gives 0 in the term (2.0 - xs.x - xs.y).
                    float jf = floor(max(x_tmp.x, x_tmp.y)) - (low_side ? 1 : 0);
                    x_tmp -= vec2(jf);
                    start.x -= jf;
                    int j = int(jf);
                    vec2 xwindow = clamp(x_tmp, 0.0, 1.0);
                    if (vec.x != 0) {
                        vec2 t = (xwindow - x_tmp.x) / vec.x;
                        ywindow = ywindow.x + t * vec.y;
                    }
                    if (j >= 0 && j < TILE_HEIGHT_PX && ywindow.x != ywindow.y) {
                        vec2 xs = swap_xy ? ywindow : xwindow;
                        vec2 ys = swap_xy ? xwindow : ywindow;

                        // Go back to the original coordinate system.
                        if (swap_xy) {
                            start = start.yx;
                        }
                        vec = seg.vector;

                        // Determine whether the segment crosses the left edge of the current pixel. We need to do this
                        // in a way that is consistent with the non-AA pass. A good way is to do the same implicit test
                        // as the non-AA pass which is a bit costly but avoids the large inaccuracy coming from the
                        // division.
                        //
                        // As n.y is normalized to either a positive value or zero, we use it for another optimization
                        // in the implicit test. The segment will never cross the left edge when it's completely
                        // vertical, so we can assume n.y > 0. The implicit test monotonically decreases as we increase
                        // the y of testing point. When the vertical crossing is both below and outside the pixel,
                        // y_edge will resolve to 1.0, which gives 0 contribution to the coverage. Therefore only
                        // testing for the top left corner is sufficient. Remember that, since n.y > 0, `dot(start, n) >
                        // 0` implies that the vertical crossing is above the corner.
                        bool has_y_edge = dot(start, n) > 0 && (start.x > 0 != start.x + vec.x > 0);
                        float y_edge = xs.x < xs.y ? ys.x : ys.y;

                        // The coverage is simply the area to the right of the segment, calculated as a trapezoid.
                        float coverage = 0.5 * (2.0 - xs.x - xs.y) * (ys.x - ys.y);
                        // Add area below the vertical crossing.
                        if (has_y_edge)
                            coverage += sign(seg.vector.x) * (1.0 - y_edge);
                        uint idx = swap_xy ? j * TILE_WIDTH_PX + i : i * TILE_WIDTH_PX + j;
                        // Use integer atomics; float atomics are typically emulated and excessively slow.
                        // There are potentially a lot of bank conflicts, but currently we don't really use shared
                        // memory that much for that to become a bottleneck. Should we need to optimize for it, it's
                        // trivial to solve by splitting the coverage map into a row-major one and column-major one.
                        atomicAdd(cov[idx], int(coverage * COV_MULTIPLIER));
                    }
                }
                tile_seg_ref = seg.next;
            } while (tile_seg_ref.offset != 0);
            barrier();
            for (uint k = 0; k < CHUNK; k++) {
                uvec2 pos = gl_LocalInvocationID.xy + chunk_offset(k);
                float aa = float(COV(pos.x, pos.y)) / COV_MULTIPLIER;
                // Add up the tile and pixel winding values to obtain the final coverage.
                area[k] = min(abs(area[k] + aa), 1.0);
            }
            cmd_ref.offset += 4 + CmdFill_size;
            break;
        case Cmd_Solid:
            for (uint k = 0; k < CHUNK; k++) {
                area[k] = 1.0;
            }
            cmd_ref.offset += 4;
            break;
        case Cmd_Alpha:
            CmdAlpha alpha = Cmd_Alpha_read(cmd_alloc, cmd_ref);
            for (uint k = 0; k < CHUNK; k++) {
                area[k] = alpha.alpha;
            }
            cmd_ref.offset += 4 + CmdAlpha_size;
            break;
        case Cmd_Color:
            CmdColor color = Cmd_Color_read(cmd_alloc, cmd_ref);
            mediump vec4 fg = unpacksRGB(color.rgba_color);
            for (uint k = 0; k < CHUNK; k++) {
                mediump vec4 fg_k = fg * area[k];
                rgba[k] = rgba[k] * (1.0 - fg_k.a) + fg_k;
            }
            cmd_ref.offset += 4 + CmdColor_size;
            break;
        case Cmd_LinGrad:
            CmdLinGrad lin = Cmd_LinGrad_read(cmd_alloc, cmd_ref);
            float d = lin.line_x * float(xy.x) + lin.line_y * float(xy.y) + lin.line_c;
            for (uint k = 0; k < CHUNK; k++) {
                vec2 chunk_xy = vec2(chunk_offset(k));
                float my_d = d + lin.line_x * chunk_xy.x + lin.line_y * chunk_xy.y;
                int x = int(round(clamp(my_d, 0.0, 1.0) * float(GRADIENT_WIDTH - 1)));
                mediump vec4 fg_rgba = imageLoad(gradients, ivec2(x, int(lin.index)));
                fg_rgba.rgb = fromsRGB(fg_rgba.rgb);
                rgba[k] = fg_rgba;
            }
            cmd_ref.offset += 4 + CmdLinGrad_size;
            break;
        case Cmd_Image:
            CmdImage fill_img = Cmd_Image_read(cmd_alloc, cmd_ref);
            mediump vec4 img[CHUNK] = fillImage(xy_uint, fill_img);
            for (uint k = 0; k < CHUNK; k++) {
                mediump vec4 fg_k = img[k] * area[k];
                rgba[k] = rgba[k] * (1.0 - fg_k.a) + fg_k;
            }
            cmd_ref.offset += 4 + CmdImage_size;
            break;
        case Cmd_BeginClip:
            for (uint k = 0; k < CHUNK; k++) {
                // We reject any inputs that might overflow in render_ctx.rs.
                // The following is a sanity check so we don't corrupt memory should there be malformed inputs.
                uint d = min(clip_depth, MAX_BLEND_STACK - 1);
                blend_stack[d][k] = packsRGB(vec4(rgba[k]));
                blend_alpha_stack[d][k] = area[k];
                rgba[k] = vec4(0.0);
            }
            clip_depth++;
            cmd_ref.offset += 4;
            break;
        case Cmd_EndClip:
            clip_depth--;
            for (uint k = 0; k < CHUNK; k++) {
                uint d = min(clip_depth, MAX_BLEND_STACK - 1);
                mediump vec4 bg = unpacksRGB(blend_stack[d][k]);
                mediump vec4 fg = rgba[k] * area[k] * blend_alpha_stack[d][k];
                rgba[k] = bg * (1.0 - fg.a) + fg;
            }
            cmd_ref.offset += 4;
            break;
        case Cmd_Jump:
            cmd_ref = CmdRef(Cmd_Jump_read(cmd_alloc, cmd_ref).new_ref);
            cmd_alloc.offset = cmd_ref.offset;
            break;
        }
    }

    for (uint i = 0; i < CHUNK; i++) {
        imageStore(image, ivec2(xy_uint + chunk_offset(i)), vec4(tosRGB(rgba[i].rgb), rgba[i].a));
    }
}
