// Copyright 2025 the Vello Authors
// SPDX-License-Identifier: Apache-2.0 OR MIT

/*
   Copyright 2024 Radzivon Bartoshyk
   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at
       http://www.apache.org/licenses/LICENSE-2.0
   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
*/

/// Optional FMA, if it is available hardware FMA will use, if not then just scalar `c + a * b`
#[inline(always)]
pub(crate) fn fmla(a: f64, b: f64, c: f64) -> f64 {
    #[cfg(any(
        all(
            any(target_arch = "x86", target_arch = "x86_64"),
            target_feature = "fma"
        ),
        all(target_arch = "aarch64", target_feature = "neon")
    ))]
    {
        f64::mul_add(a, b, c)
    }
    #[cfg(not(any(
        all(
            any(target_arch = "x86", target_arch = "x86_64"),
            target_feature = "fma"
        ),
        all(target_arch = "aarch64", target_feature = "neon")
    )))]
    {
        a * b + c
    }
}

#[inline]
fn newtons_method(y: f64, a: f64) -> f64 {
    let y2 = y * y;
    let y3 = y2 * y;
    let y6 = y3 * y3;
    let r = a / y6;
    let num = r + 5.;
    // y (a/y^6 + 5) / 6
    (num * (1. / 6.)) * y
}

#[inline]
fn fast_ldexp(d: f64, i: i32) -> f64 {
    let mut u = d.to_bits();
    u = u.wrapping_add((i as u64).wrapping_shl(52));
    f64::from_bits(u)
}

pub(crate) fn sixth_root(x: f32) -> f32 {
    let ix = x.to_bits();

    // filter out exceptional cases
    if ix >= 0xff_u32 << 23 || ix == 0 {
        if ix.wrapping_shl(1) == 0 {
            return 0.;
        }
        if (ix >> 31) != 0 {
            return f32::NAN;
        }
        if ix.wrapping_shl(9) == 0 {
            return 0.;
        }
        return x + x; // nan
    }

    let exp = ((ix >> 23) & 0xff) as i32;
    let mut e = exp;
    let mut mant = ix & ((1_u32 << 23) - 1);

    // Normalize subnormal
    if exp == 0 {
        let norm = x * f32::from_bits(0x4b800000); // * 2^24
        let norm_bits = norm.to_bits();
        mant = norm_bits & ((1_u32 << 23) - 1);
        e = ((norm_bits >> 23) & 0x7ff) as i32 - 24;
    }

    // Unbias exponent
    e -= 127;

    // Restore implicit leading 1 for normal numbers
    mant |= 0x7f << 23; // 0x7f = 127 -> exponent of 0 in biased form
    let m = f32::from_bits(mant) as f64;

    // split exponent e = 6*q + r with r in {0,1,2,4,5}
    // use div_euclid/rem_euclid to get r >= 0
    let q = e.div_euclid(6);
    let rem_scale = e.rem_euclid(6);

    // initial guess, estrin scheme

    // Polynomial generated by Sollya:
    // d = [1.0, 2.0];
    // f_root6 = x^(1/6);
    // Q = fpminimax(f_root6, 4, [|D...|], d, relative, floating);
    const C: [u64; 5] = [
        0x3fe76acf3da4521c,
        0x3fda7b37caf775d8,
        0xbfc923c79d43baba,
        0x3fadc0e4139bd21b,
        0xbf7dbc63861d5ca5,
    ];

    let m2 = m * m;

    let p01 = fmla(m, f64::from_bits(C[1]), f64::from_bits(C[0]));
    let p23 = fmla(m, f64::from_bits(C[3]), f64::from_bits(C[2]));
    let t = fmla(m2, f64::from_bits(C[4]), p23);
    let guess = fmla(m2, t, p01);

    // 1; 2^{1/6}; 2^{2/6}; 2^{3/6}; 2^{4/6}; 2^{5/6}
    static ESCALE: [u64; 6] = [
        1.0_f64.to_bits(),
        0x3ff1f59ac3c7d6c0,
        0x3ff428a2f98d728b,
        0x3ff6a09e667f3bcd,
        0x3ff965fea53d6e3c,
        0x3ffc823e074ec129,
    ];

    let z = guess * f64::from_bits(ESCALE[rem_scale as usize]);

    let mm = fast_ldexp(m, rem_scale); // bring domain into [1;8]
    let y0 = newtons_method(z, mm);
    fast_ldexp(y0, q) as f32
}
